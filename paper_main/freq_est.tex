\section{Frequency and Phase Estimation}%
\label{sec:freq_est}

Frequency and phase estimation, also called carrier synchronization, is the next step after detection for coherent demodulation.
In this section, we discuss the estimation algorithm by assuming the time synchronization of the preamble is perfect, i.e., 
the observation window contains the complete preamble. For the same reason as in the detection section, we first derive the estimator
by assuming the effect of the fractional delay in signal model~\eqref{eq:model} is neglected.
In simulation section, we will discuss how much the value of fractional delay degrades the estimating accuracy of estimators by
comparing with different sampling rate.

For estimating frequency offset $\delta$ and the phasor $S=Ae^{j\phi}$, the maximum likelihood (ML) estimate of the parameters in~\eqref{eq:model} is given by

\begin{equation}
\label{eq:ML_f_S}
  \hat{\delta},\hat{S}=\min_{\delta,S=Ae^{j\phi}}\sum_{n=0}^{N-1}|r_n-s_nSe^{j2\pi\delta n}|^{2}.
\end{equation}
% extension to reviewer 1, comment 3
By taking the Wirtinger derivative with respect to $S$ and setting it equal to zero, a 
closed form for the estimated phasor $\hat{S}$ is readily derived,

\begin{equation}
    \label{eq:opt_S}
    \hat{S}=\frac{\sum_{n=0}^{N-1}{r_{n}s_n^{*}e^{-j2\pi\hat{\delta} n}}}{\sum_{n=0}^{N-1}|s_{n}|^2},
  \end{equation}
and $\hat{\phi}=\arg\{S\}$. We see the estimate of phasor $\hat{S}$ relies on the estimate of frequency $\hat{\delta}$ at $\bar{p}$.
It is shown later the derivation of $\hat{\delta}$ also plugs in the expression of phasor estimate in~\eqref{eq:opt_S}. Thus, the estimators for frequency and phasor are
joint estimators. Moreover, by plugging~\eqref{eq:opt_S} in~\eqref{eq:generalized_corr}, the GLRT based detector finally reduces to

\begin{equation}
  \label{eq:reduced_GLRT_detector}
  \rho(p)=
  \frac{|\hat{S}_p|}
  {||\bm{r}_{p}||\cdot||\bm{s}||} \LRT{H_1}{H_0} \gamma
\end{equation}
where $||\bm{s}||$ denotes Euclidean norm of the preamble. The most benefit of~\eqref{eq:reduced_GLRT_detector} against to
~\eqref{eq:generalized_corr} is the greatly decrease of compu-tational complexity.

% extension to reviewer 1, comment 3, reviewer 3, comment 4
The frequency estimate is obtained similarly as the zero of the
derivative of~\eqref{eq:ML_f_S},

\begin{equation}
    \label{eq:intm_neces_cond1}
    \sum_{n=0}^{N-1}{(r_{n}s_n^{*}S^{*}ne^{-j2\pi \delta n}-s_ns_n^{*}n)=0}.
    \end{equation}
Note $\sum_{n=0}^{N-1}{s_ns_n^{*}n}$ is real
valued, which results in the imaginary part of left hand side of~\eqref{eq:intm_neces_cond1} be zero;
By plugging the estimate for $S$ of~\eqref{eq:opt_S} into~\eqref{eq:intm_neces_cond1} and rearranging the order of indexes, yields

\begin{equation}
    \label{eq:intm_neces_cond2}
    \Im\bigg\{\sum_{m=0}^{N-1}{\sum_{n=0}^{N-1}{nr_{n}r_{m}^{*}s_n^{*}s_me^{j2\pi \delta(m-n)}}}\bigg\} = 0.
  \end{equation}
A change of variables lets us focus on the difference between sampling instances $m$ and $n$.
With $k=m-n$,~\eqref{eq:intm_neces_cond2} becomes

\begin{equation}
    \label{eq:intm_neces_cond3}
    \Im\bigg\{\sum_{m=0}^{N-1}{\sum_{k{=}m-(N-1)}^{m}{(m{-}k)r_{m-k}r_{m}^{*}s_{m-k}^{*}s_me^{j2\pi \delta k}}}\bigg\}=0.
  \end{equation}
Reversing the order of summation in~\eqref{eq:intm_neces_cond3}, we get

\begin{equation}
    \begin{aligned}
    \label{eq:intm_neces_cond4}
    \Im\bigg\{&\sum_{k=-(N-1)}^{0}\sum_{m=0}^{N-1+k}{(m{-}k)r_{m-k}r_{m}^{*}s_{m-k}^{*}s_me^{j2\pi \delta k}+}\\
    &\sum_{k=1}^{N-1}\sum_{m=k}^{N-1}{(m{-}k)r_{m-k}r_{m}^{*}s_{m-k}^{*}s_me^{j2\pi \delta k}}\bigg\}= 0.
    \end{aligned}
  \end{equation}
The term for $k{=}0$ in~\eqref{eq:intm_neces_cond4} can be eliminated since it is real-valued. For $k \neq 0$, the positive and negative indices $k$ are symmetric. 
After grouping terms appropriately, the necessary condition for $\hat{\delta}$ is given by

\begin{equation}
    \label{eq:delta}
    J(\hat{\delta}) = \Im\bigg\{\sum_{k=1}^{N-1}{\sum_{m=k}^{N-1}{kr_{m-k}r_m^{*}s_{m-k}^{*}s_m}e^{j2\pi\hat{\delta}k}}\bigg\}=0.
    \end{equation}
This expression is fundamentally equivalent to conditions provided by Luise and Reggiannini~\cite{Luise_Reggiannini_95} and Fitz~\cite{Fitz_94}.
However,~\eqref{eq:delta} explicitly allows for pulse shaping and oversampling.

The estimator $\hat{\delta}$ in~\eqref{eq:delta} has no closed-form
solution.
In~\cite{Luise_Reggiannini_95}, it is approximated by replacing the exponential with its
Taylor series expansion.
In~\cite{Fitz_94}, an approximate solution is obtained via Euler's
identity for large $N$.
Both solutions have computational complexity $O(N^2)$ reflecting the
double summation.

We propose a family of alternative solutions to~\eqref{eq:delta}.
A solution with $O(N)$ complexity is used for operating at the sample
rate during the sequential GLRT detection;
it prioritizes low complexity at the expense of some loss of accuracy.
A second solution is used to improve the estimation accuracy for coherent demodulation once the preamble has been detected.

\subsection{Solution I: Single-Difference (SD) Estimator}

The first estimator is rooted in the insight that at high SNR environment, every lag $k$ in~\eqref{eq:delta} can be used to
approximate the true frequency offset $\bar{\delta}$. Assume noise is very small, i.e.,
$r_m \approx s_mAe^{j(2\pi \bar{\delta} m+\phi)}$, and~\eqref{eq:delta} can be expanded to

\begin{equation}
    \label{eq:delta_extens_no_noise}
    \Im\bigg\{A^2\sum_{k=1}^{N-1}\sum_{m=k}^{N-1}k|s_{m-k}|^2|s_m|^2e^{j2\pi (\hat{\delta}-\bar{\delta})k}\bigg\}=0.
    \end{equation}
Note that in~\eqref{eq:delta_extens_no_noise} the inner summation is purely real for every lag~$k$ if $\hat{\delta}=\bar{\delta}$.
This observation suggests that an unbiased estimate of the frequency offset can be obtained by using only a single lag~$k$
from~\eqref{eq:delta}. The approach lowers the complexity from $O(N^2)$ to $O(N)$ and permits a closed-form solution for $\hat{\delta}$.  

\subsubsection{Closed-form expression} 
For one lag $k$, the SD estimator is given by
\begin{equation}
    \label{eq:delta_SD}
    \est{\delta}{\sd}(k)=-\frac{\arg\big\{\sum_{m=k}^{N-1}r_{m-k}r_m^*s_{m-k}^*s_m\big\}}{2\pi k}.
\end{equation}

\subsubsection{Choice of lag $k$}
In low (or moderate) SNR environment, i.e., noise effect cannot be ignored, the argument of numerator in~\eqref{eq:delta_SD} can be extended to 

\begin{equation}
    \label{eq:delta_extens_w_noise}
    \begin{aligned}
      \sum_{m=k}^{N-1}&r_{m-k}r_m^*s_{m-k}^*s_m= \sum_{m=k}^{N-1} \Big( A^2|s_{m-k}|^2|s_m|^2e^{-j2\pi \bar{\delta} k} + \\
      &w_m^* S|s_{m-k}|^2s_m e^{j2\pi \bar{\delta}(m-k)} + w_{m-k}S^*|s_m|^2s_{m-k}^* e^{-j2\pi \bar{\delta} m} + \\
      &w_{m-k}w_m^*s_{m-k}^*s_m \Big) .
    \end{aligned}
    \end{equation}
To interpret~\eqref{eq:delta_extens_w_noise}, recognize that the first term of right hand side is
deterministic and provides the mean of the expression.
The last term can be neglected even at moderate SNR since the
factors in the product are uncorrelated (as long as $k \neq 0$).
The two middle terms yield a zero-mean, complex Gaussian random variable.
If we denote the expression in~\eqref{eq:delta_extens_w_noise} as random variable $W(k)$,
then these observations can be summarized as
% ask for more details are lack of. 

\begin{equation}
    \label{eq:ori_pdf_W}
    W(k) \sim \cn\bigg((
    \frac{N{-}k}{A^2}){(\frac{E_s}{M})}^2e^{-j2\pi \bar{\delta} k},
    2(\frac{N{-}k}{A^4})\frac{N_0}{2}{(\frac{E_s}{M})}^3\bigg).
  \end{equation}
Here $A^2|s_m|^2 {\approx} E_s/M$ denotes the average energy per
sample.

Recall from~\eqref{eq:delta_SD} the estimator $\hat{\delta}_{\text{SD}}(k)$ requires $\arg\{W(k)\}$.
The full pdf of $\arg\{W(k)\}$ is derived in the appendix \ref{AL}
where it is also shown that a good approximation, valid for moderate SNR, 
is Gaussian. Specifically 

\begin{equation}
    \label{eq:sol_pdf_W}
    \arg\{W(k)\} \sim \n\bigg(\angle \mu_{W(k)},\frac{\sigma^2_{W(k)}}{|\mu_{W(k)}|^2}\bigg).
  \end{equation}
$\mu_{w(k)}$ and $\sigma^2_{W(k)}$ are the mean and variance of $W(k)$ provided in~\eqref{eq:ori_pdf_W}.
By plugging~\eqref{eq:ori_pdf_W},~\eqref{eq:sol_pdf_W} into~\eqref{eq:delta_SD}, the SD estimator
is approximately Gaussian distributed at moderate SNR with pdf

\begin{equation}
    \label{eq:pdf_delta}
        \est{\delta}{\sd}(k) \sim \n \bigg(\bar{\delta},\frac{M}{4\pi^2k^2(N{-}k)E_s/N_0}\bigg).
  \end{equation}  
We can see that $\hat{\delta}_{\text{SD}}(k)$ is unbiased. Moreover, the lag $k$ affects the variance of the SD estimator. 
The best choice is to choose $k=\lfloor\frac{2}{3}N\rfloor$ to minimize the variance.

It should be noted that, to prevent "aliasing" of the frequency estimate, it's also required to choose the lag $k$ small enough to ensure $2\pi |\bar{\delta}| k < \pi$.
Assuming an upper bound $\delta_{\text{max}}$ on the normalized frequency offset is available, 
the optimal choosing policy for lag $k_{\opt}$ is refined as

\begin{equation}
    \label{eq:est_k_opt}
    k_{\opt}=\left\{
      \begin{array}{cl}
        \lfloor\frac{2}{3}N\rfloor
        & \text{for $\frac{1}{2\delta_{\max}}>\lfloor\frac{2}{3}N\rfloor$} \\
        \lceil\frac{1}{2\delta_{\max}}-1\rceil
        & \text{for $\frac{1}{2\delta_{\max}} \leq\lfloor\frac{2}{3}N\rfloor$},
      \end{array}
    \right.
  \end{equation}
where $\lfloor \cdot \rfloor$ and $\lceil \cdot \rceil$ are the floor and ceil operation, respectively.

\subsubsection{Low-SNR Improvement}
Recall the SD estimator is introduced by assuming SNR is relatively high. 
The accuracy of the SD estimator may also be crucial at low SNR.
One way to improving it is by averaging $K$ estimates of SD with different lags $k$.
We call the resulting estimator the $K-$SD estimator, $\est{\delta}{K\text{-SD}}$.
In this case, we trade off a $K$-fold increase in computational complexity for lower variance.

Let $\bm{u}$ be a vector of non-negative, with
$\sum_{k \in {\cal K}}u_k=1$; here ${\cal K}$ represents the set of $K$
lags to be averaged.
% extension to reviewer 1, comment 5, reviewer 3, comment 4
Simple linear combining of $K$ SD estimators yields the $K-$SD estimator

\begin{equation}
  \label{eq:K_SD_est}
      \est{\delta}{K\text{-SD}}=\sum_{k \in \cal K}\est{\delta}{\sd}(k)u_k.
\end{equation}
The optimal weight vector $\bm{u}_\opt$ can be obtained by minimizing the variance of $\est{\delta}{K\text{-SD}}$,
which is well-known as

\begin{equation}
  \label{eq:u_opt}
      \bm{u}_\opt=\frac{\bm{C}^{-1}\bm{1}}{\bm{1}^T\bm{C}^{-1}\bm{1}}.
\end{equation}
$\bm{C}$ is the autocovariance matrix between the $K$ SD estimators and $\bm{1}$ represents the column vector of one. 
Unfortunately, it is generally difficult to know the full information of $\bm{C}$. However,
If the lags $k \in {\cal K}$ are chosen to satisfy the spacing between any pair is at least
equal to the oversampling factor $M$, then the estimates to be combined are approximately uncorrelated and unbiased; The  
resulting $\bm{C}$ is a diagonal matrix of variance of each SD estimator. For example, a good choice for selecting 3 lags is 
${\cal K}=\{k_\opt-M,k_\opt,k_\opt+M\}$. The optimal weights $\bm{u}_\opt$ are proportional to the inverse of the
variances in~\eqref{eq:pdf_delta}.

\subsection{Solution II: Newton-Method (NM) Estimator}

The SD estimator emphasizes low-complexity property and is intended to provide merely sufficiently good carrier synchronization
to enable coherent detection. Once the signal has been acquired, the SD estimator can be improved by 
investing additional computations. Since detection events are rare, the computational complexity is of little concern.

The principle is to use the SD (or $K-$SD) estimator as the starting point for a Newton-type iteration 
aimed at finding a better solution to the necessary condition~\eqref{eq:delta}. 
In principle, multiple iterations are possible to produce successively better approximations to the root of
$\J(\hat{\delta})$ in~\eqref{eq:delta}. Specifically, the iterations are given by

\begin{equation}
    \label{eq:iter_NM_est}
    \est{\delta}{\nm}^{(i+1)}=\est{\delta}{\nm}^{(i)}-
    \frac{\J(\est{\delta}{\nm}^{(i)})}{\J^\prime(\est{\delta}{\nm}^{(i)})}
  \end{equation}
where $\est{\delta}{\nm}^{(0)}~{=}~\est{\delta}{\sd}(k_{\opt})$ is the starting point of the iteration and
$\J^\prime(\cdot)$ denotes the derivative of $\J$ with respect to $\hat{\delta}$. Specifically,

\begin{equation}
    \label{eq:derivative of delta}
    J^\prime(\hat{\delta}) = \Im\bigg\{\sum_{k=1}^{N-1}{\sum_{m=k}^{N-1}{j2\pi k^2r_{m-k}r_m^{*}s_{m-k}^{*}s_m}e^{j2\pi\hat{\delta}k}}\bigg\}.
    \end{equation}
Our simulations indicate that only a single iteration is usually sufficient to achieve very good accuracy.


